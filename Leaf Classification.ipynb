{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#importing the required packages\n",
    "\n",
    "import cv2\n",
    "from skimage import data, io, filters\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Reading the train and test data\n",
    "\n",
    "train = pd.read_csv('D:\\Kaggle Projects\\Leaf Classification\\\\train\\\\train.csv')\n",
    "test_1 = pd.read_csv('D:\\Kaggle Projects\\Leaf Classification\\\\test\\\\test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking the Id columns from train and Test as well as species from train data \n",
    "train_head = train.iloc[:,0]\n",
    "test_head = test_1.iloc[:,0]\n",
    "train_species = train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_species =  le.fit_transform(train.species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Initializing the List of the different values \n",
    "lst_area = []\n",
    "lst_perimeter = []\n",
    "ratio = []\n",
    "extent_1 = []\n",
    "diameter = []\n",
    "\n",
    "\n",
    "# Initializing the path of the Different images \n",
    "\n",
    "path = \"D:\\\\Kaggle Projects\\\\Leaf Classification\\\\images\\\\\"\n",
    "\n",
    "#Generating the values of Area , perimeter, diameter using the loop passing id's in the train data\n",
    "for values in train_head:\n",
    "    #Getting the values from the train header file \n",
    "    num = values\n",
    "    #Converting the values in the string so that it can be further be added to another string \n",
    "    num = str(num)\n",
    "    # Adding the Extention to the file path \n",
    "    val = num + '.jpg'\n",
    "    #Taking the full path values in the val2 \n",
    "    val2 = path+val\n",
    "    # Reading the Image from the file \n",
    "    img = cv2.imread(val2,0)\n",
    "    # Extracting the Different features from the Images \n",
    "    ret,thresh = cv2.threshold(img,127,255,0)\n",
    "    # Getting the contour from the image \n",
    "    contours,hierarchy = cv2.findContours(thresh,1,2)\n",
    "    cnt = contours[0]\n",
    "    M = cv2.moments(cnt)\n",
    "    # Getting the Contour ARea from the Image \n",
    "    area = cv2.contourArea(cnt)\n",
    "    area = round(area, 2)\n",
    "    # Appending diffrent ares in the image \n",
    "    lst_area.append(area)\n",
    "    # Same caclulation for perimeter , aspect ratio and diameter and further add them in the list\n",
    "    perimeter = cv2.arcLength(cnt,True)\n",
    "    perimeter = round(perimeter, 2)\n",
    "    lst_perimeter.append(perimeter)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w)/h\n",
    "    ratio.append(aspect_ratio)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    extent = round(extent, 2)\n",
    "    extent_1.append(extent)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "    diameter.append(equi_diameter)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the Perimeter , Area , Ratio , Extent and Diameter Diffrent values from list to data frame and renaming the column in the\n",
    "# Data Frame\n",
    "Perimeter_train  = pd.DataFrame(lst_perimeter)\n",
    "Perimeter_train.columns = ['Perimeter']\n",
    "Area_train  = pd.DataFrame(lst_area)\n",
    "Area_train.columns = ['Area']\n",
    "Ratio_train  = pd.DataFrame(ratio)\n",
    "Ratio_train.columns = ['Ratio']\n",
    "Extent_train  = pd.DataFrame(extent_1)\n",
    "Extent_train.columns = ['Extent']\n",
    "Dia_train  = pd.DataFrame(diameter)\n",
    "Dia_train.columns = ['Diameter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same as above Train Data\n",
    "\n",
    "lst_area = []\n",
    "lst_perimeter = []\n",
    "ratio = []\n",
    "extent_1 = []\n",
    "diameter = []\n",
    "size = []\n",
    "\n",
    "path = \"D:\\\\Kaggle Projects\\\\Leaf Classification\\\\images\\\\\"\n",
    "\n",
    "#Generating the values of Area , perimeter, diameter using the loop passing id's in the train data\n",
    "for values in test_head:\n",
    "    num = values\n",
    "    num = str(num)\n",
    "    val = num + '.jpg'\n",
    "    val2 = path+val\n",
    "    img = cv2.imread(val2,0)\n",
    "    ret,thresh = cv2.threshold(img,127,255,0)\n",
    "    contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    cnt = contours[0]\n",
    "    M = cv2.moments(cnt)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    area = round(area, 2)\n",
    "    lst_area.append(area)\n",
    "    perimeter = cv2.arcLength(cnt,True)\n",
    "    perimeter = round(perimeter, 2)\n",
    "    lst_perimeter.append(perimeter)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w)/h\n",
    "    ratio.append(aspect_ratio)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    rect_area = w*h\n",
    "    extent = float(area)/rect_area\n",
    "    extent = round(extent, 2)\n",
    "    extent_1.append(extent)\n",
    "    equi_diameter = np.sqrt(4*area/np.pi)\n",
    "    diameter.append(equi_diameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding the Perimeter , Area , Ratio , Extent and Diameter Diffrent values from list to data frame and renaming the column in the\n",
    "# Data Frame\n",
    "Perimeter_test  = pd.DataFrame(lst_perimeter)\n",
    "Perimeter_test.columns = ['Perimeter']\n",
    "Area_test  = pd.DataFrame(lst_area)\n",
    "Area_test.columns = ['Area']\n",
    "Ratio_test  = pd.DataFrame(ratio)\n",
    "Ratio_test.columns = ['Ratio']\n",
    "Extent_test  = pd.DataFrame(extent_1)\n",
    "Extent_test.columns = ['Extent']\n",
    "Dia_test  = pd.DataFrame(diameter)\n",
    "Dia_test.columns = ['Diameter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Droping the Species Column as we have converted the Species from categorical values to numerical values \n",
    "train_new = train.drop('species', 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Adding the below findings from the Images to the Data frame , i.e train file \n",
    "\n",
    "train_new['Perimeter'] =  Perimeter_train\n",
    "train_new['Area'] =  Area_train\n",
    "train_new['Ratio'] =  Ratio_train\n",
    "train_new['Extent'] =  Extent_train\n",
    "train_new['Diameter'] =  Dia_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Adding the below findings from the Images to the Data frame , i.e test file \n",
    "test_1['Perimeter'] =  Perimeter_test\n",
    "test_1['Area'] =  Area_test\n",
    "test_1['Ratio'] =  Ratio_test\n",
    "test_1['Solidity'] =  Extent_test\n",
    "test_1['Diameter'] =  Dia_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encoding the Diffrent categorical species to the NUmerical values\n",
    "# for example Acer_Opalus to 1 , Quercus_Hartwissiana to 2 like wise\n",
    "label = LabelEncoder().fit(train['species'])\n",
    "y_train = label.transform(train['species'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the Data into the Scaler format \n",
    "# Scaler fit means all the variances been ajusted i.e normalized the Data \n",
    "# Both train and Test Data be Standarized \n",
    "scaler = StandardScaler().fit(train_new)\n",
    "x_train = scaler.transform(train_new)\n",
    "scaler = StandardScaler().fit(test_1)\n",
    "x_test = scaler.transform(test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0008, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating the model\n",
    "# Using Multinomial function as we have different categorical values as well as tuned the parameter by taking the\n",
    "#C as 1000 and tol as 0.0008 \n",
    "# In the above two kernals we have used lbfgs for better performance\n",
    "clf = LogisticRegression(solver='lbfgs' , multi_class='multinomial', C=1000, tol=0.0008)\n",
    "clf.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010101010101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Printing the Model score from both train and test data \n",
    "print(clf.score(train_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predicting the values using the trained model\n",
    "y_test = clf.predict_proba(x_test)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "# Generating the subm,ission file and save it to the specific location\n",
    "submission = pd.DataFrame(y_test, index=test_head, columns=le.classes_)\n",
    "submission.to_csv('D:\\Kaggle Projects\\Leaf Classification\\\\submission_model.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
